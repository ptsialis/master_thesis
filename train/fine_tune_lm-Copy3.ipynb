{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2459ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trl\n",
      "  Downloading trl-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.1.dev0+gba5374836.d20240125)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
      "Collecting huggingface-hub>=0.19.4 (from datasets)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.0a0+81ea7a4)\n",
      "Collecting safetensors (from peft)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Downloading tyro-0.7.3-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.8.1-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m166.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m137.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: xxhash, shtab, safetensors, pyarrow-hotfix, docstring-parser, dill, responses, multiprocess, huggingface-hub, tyro, tokenizers, bitsandbytes, accelerate, transformers, datasets, trl, peft, evaluate\n",
      "\u001b[33m  WARNING: The script shtab is installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts accelerate, accelerate-config, accelerate-estimate-memory and accelerate-launch are installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script trl is installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/raid-data/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed accelerate-0.28.0 bitsandbytes-0.43.0 datasets-2.18.0 dill-0.3.8 docstring-parser-0.16 evaluate-0.4.1 huggingface-hub-0.22.2 multiprocess-0.70.16 peft-0.10.0 pyarrow-hotfix-0.6 responses-0.18.0 safetensors-0.4.2 shtab-1.7.1 tokenizers-0.15.2 transformers-4.39.3 trl-0.8.1 tyro-0.7.3 xxhash-3.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets peft datasets transformers trl bitsandbytes accelerate evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3beb1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-17:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Process ForkProcess-12:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-13:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-11:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import subprocess as sp\n",
    "from peft import LoraConfig,prepare_model_for_kbit_training,get_peft_model\n",
    "from trl import SFTTrainer,DataCollatorForCompletionOnlyLM\n",
    "import subprocess as sp\n",
    "from data.serialize import deserialize_str,SerializerSettings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec82d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0d1809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c89089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from Hugging Face hub\n",
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "#meta-llama/Llama-2-70b-chat-hf\n",
    "# New instruction dataset\n",
    "guanaco_dataset = \"final_experiments/datasets/Normalized_Encoded_test_dataset.json\"\n",
    "\n",
    "# Fine-tuned model\n",
    "new_model = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81704c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd85f9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5951, 4005, 4035, 6251]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "314583ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=guanaco_dataset, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e3ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3af12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['median', 'dataset_desc', 'min', 'output', 'len_main_part', 'len_forecasting_part', 'input', 'dataset_name', 'max'],\n",
       "        num_rows: 934\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['median', 'dataset_desc', 'min', 'output', 'len_main_part', 'len_forecasting_part', 'input', 'dataset_name', 'max'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61784206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69746e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0666610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\",\n",
    "    token = access_token,\n",
    "    use_cache = False\n",
    ")\n",
    "#model.config.use_cache = False\n",
    "#model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7f0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab2a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True, token= access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20704415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aeec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "'<|start_prompt|> Dataset description:The data was generated as part of a student project where four students performed four activities whilst wearing a smart watch. Participants were required to record motion a total of five times, and the data is sampled once every tenth of a second,for a ten second period. Task description: forecast the next 10 steps given the previous 90 steps information: - 1 0 6,  - 1 0 6,  - 4 3 9,  6 4 7,  - 6 8 9,  - 4 3 6,  2 9 6 4,  2 5 1 6,  2 5 0 6,  - 9 5 0,  - 2 0 5 0,  - 1 3 3 7,  - 1 3 3 7,  - 5 5 3,  - 2 9 2,  2 6 9 2,  2 6 9 2,  3 7 9 5,  - 5,  - 1 2 3 3,  - 1 2 3 3,  - 5 5 3,  - 1 3 5 5,  - 8 2,  2 4 7 4,  4 0 6 9,  4 7 9,  - 1 0 6 2,  - 2 0 8 8,  - 1 0 0 6,  - 9 4 2,  - 1 3 9 8,  - 1 3 9 8,  5 3 0 2,  2 1 8 9,  - 2 5 4 0,  - 8 2 0,  1 0,  - 2 8 4,  - 1 7 6 5,  6 7 1,  2 9 0 8,  1 3 0 5,  7 2 7,  - 1 6 5 3,  - 1 6 5 3,  - 1 2 7 0,  - 7 4 3,  - 1 2 3 5,  - 5 4 3,  2 1 1 2,  2 8 6 5,  5 5 3,  - 1 2 8 9,  - 1 1 7 4,  - 1 4 9 1,  7 1,  - 9 1 0,  - 1 4 6,  1 9 4 6,  2 4 8 7,  7 2 4,  - 1 5 6 8,  - 1 1 6 9,  - 2 3 5 7,  - 1 9 2 0,  - 1 2 2 7,  1 2 0 1,  3 1 3 2,  1 7 0,  - 1 7 6 8,  - 1 5 6 6,  - 9 1 0,  - 9 1 0,  - 1 7 1 5,  - 1 7 1 5,  - 2 7 4 3,  7 7 7,  2 6 3 1,  1 3 6 6,  - 1 1 1 8,  6 3 1,  - 1 4 2 4,  - 7 4 5,  - 6 0 7,  - 4 6 0,  1 8 5 3,  1 3 6 3,  - 1 7 0,  - 6 0 4,  <|<end_prompt>|> Answer:  - 1 4 4 6,  2 8 7,  - 1 6 1 6,  3 1 6,  3 2 1 7,  2 4 9 0,  - 5 8,  - 5 8,  - 2 7 4,  - 2 7 4,  /n /// <|start_prompt|> Dataset description:The data was generated as part of a student project where four students performed four activities whilst wearing a smart watch. Participants were required to record motion a total of five times, and the data is sampled once every tenth of a second,for a ten second period. Task description: forecast the next 10 steps given the previous 90 steps information: 7 5 6,  7 5 6,  - 9 2 1 6,  - 5 9 7 7,  - 3 7 1 1,  - 3 7 1 1,  7 3 1,  1 0 7 0,  5 8 2,  6 5 6,  7 3 8,  7 3 8,  6 2 3,  6 2 3,  3 4 2,  3 4 2,  4 8 7,  4 8 0,  4 3 0,  4 4 7,  2 4 9,  2 4 2,  4 5 0,  3 0 9,  8 3,  2 9 2,  3 1 1,  5 4 3,  6 9 8,  4 7 5,  3 5 3,  1 3 1,  7 6,  3 8 5,  3 4 4,  2 1 2,  8,  - 1 5 8,  3 5,  5 0 8,  6 2 1,  3 1 9,  - 8 5,  - 8 5,  - 2 4,  2 7 5,  3 3 5,  2 3 7,  - 2,  - 7,  - 1 1,  1 0 1,  8 8,  1 2 3,  1,  1 5,  5 9,  9 0,  2 4 2,  9 9,  4 5,  9 1,  2 1,  9 7,  1 9,  6 7,  2 4,  2 4,  4,  2 0 0,  2 0 0,  2 0 0,  - 1 0 0,  - 1 0 0,  5,  5,  - 1 3 8,  5 3,  3 0 4,  2 0 0,  4 1,  - 2 4 5,  - 1 6 4,  - 1 0 8,  - 1 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65ff80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7a8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e19ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(sample):\n",
    "    output_texts = []\n",
    "    for i in range(len(sample['input'])):\n",
    "        bos_token = \"<s>\"\n",
    "        eos_token = \"</s>\"\n",
    "        response = sample[\"output\"][i]\n",
    "        input = sample[\"input\"][i]\n",
    "\n",
    "        full_prompt = \"\"\n",
    "        full_prompt += bos_token\n",
    "        full_prompt += \"Dataset description:The data was generated as part of a student project where four students performed four activities whilst wearing a smart watch. Participants were required to record motion a total of five times, and the data is sampled once every tenth of a second,for a ten second period. Task description: forecast the next 10 steps given the previous 90 steps information: - 1 0 6,  - 1 0 6,  - 4 3 9,  6 4 7,  - 6 8 9,  - 4 3 6,  2 9 6 4,  2 5 1 6,  2 5 0 6,  - 9 5 0,  - 2 0 5 0,  - 1 3 3 7,  - 1 3 3 7,  - 5 5 3,  - 2 9 2,  2 6 9 2,  2 6 9 2,  3 7 9 5,  - 5,  - 1 2 3 3,  - 1 2 3 3,  - 5 5 3,  - 1 3 5 5,  - 8 2,  2 4 7 4,  4 0 6 9,  4 7 9,  - 1 0 6 2,  - 2 0 8 8,  - 1 0 0 6,  - 9 4 2,  - 1 3 9 8,  - 1 3 9 8,  5 3 0 2,  2 1 8 9,  - 2 5 4 0,  - 8 2 0,  1 0,  - 2 8 4,  - 1 7 6 5,  6 7 1,  2 9 0 8,  1 3 0 5,  7 2 7,  - 1 6 5 3,  - 1 6 5 3,  - 1 2 7 0,  - 7 4 3,  - 1 2 3 5,  - 5 4 3,  2 1 1 2,  2 8 6 5,  5 5 3,  - 1 2 8 9,  - 1 1 7 4,  - 1 4 9 1,  7 1,  - 9 1 0,  - 1 4 6,  1 9 4 6,  2 4 8 7,  7 2 4,  - 1 5 6 8,  - 1 1 6 9,  - 2 3 5 7,  - 1 9 2 0,  - 1 2 2 7,  1 2 0 1,  3 1 3 2,  1 7 0,  - 1 7 6 8,  - 1 5 6 6,  - 9 1 0,  - 9 1 0,  - 1 7 1 5,  - 1 7 1 5,  - 2 7 4 3,  7 7 7,  2 6 3 1,  1 3 6 6,  - 1 1 1 8,  6 3 1,  - 1 4 2 4,  - 7 4 5,  - 6 0 7,  - 4 6 0,  1 8 5 3,  1 3 6 3,  - 1 7 0,  - 6 0 4,  <|<end_prompt>|> Answer:  - 1 4 4 6,  2 8 7,  - 1 6 1 6,  3 1 6,  3 2 1 7,  2 4 9 0,  - 5 8,  - 5 8,  - 2 7 4,  - 2 7 4,  /n ///\"\n",
    "        full_prompt += f\"### Instruction: Dataset description:{sample['dataset_desc'][i]}. Statistics: The input has a minimum of {sample['min'][i]} , a maximum of {sample['max'][i]}, , and a median of {sample['median'][i]} . Task description: forecast the next {sample['len_forecasting_part'][i]} steps given the previous {sample['len_main_part'][i]} steps information: {sample['input'][i]}\"\n",
    "        #full_prompt += \"\\n\\n### Input:\"\n",
    "        full_prompt +=  input\n",
    "        #full_prompt += \"\\n\\n### Response:\"\n",
    "        full_prompt +=  response\n",
    "        full_prompt += eos_token\n",
    "        output_texts.append(full_prompt)\n",
    "\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "619635a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Dataset description:The data was generated as part of a student project where four students performed four activities whilst wearing a smart watch. Participants were required to record motion a total of five times, and the data is sampled once every tenth of a second,for a ten second period. Task description: forecast the next 10 steps given the previous 90 steps information: - 1 0 6,  - 1 0 6,  - 4 3 9,  6 4 7,  - 6 8 9,  - 4 3 6,  2 9 6 4,  2 5 1 6,  2 5 0 6,  - 9 5 0,  - 2 0 5 0,  - 1 3 3 7,  - 1 3 3 7,  - 5 5 3,  - 2 9 2,  2 6 9 2,  2 6 9 2,  3 7 9 5,  - 5,  - 1 2 3 3,  - 1 2 3 3,  - 5 5 3,  - 1 3 5 5,  - 8 2,  2 4 7 4,  4 0 6 9,  4 7 9,  - 1 0 6 2,  - 2 0 8 8,  - 1 0 0 6,  - 9 4 2,  - 1 3 9 8,  - 1 3 9 8,  5 3 0 2,  2 1 8 9,  - 2 5 4 0,  - 8 2 0,  1 0,  - 2 8 4,  - 1 7 6 5,  6 7 1,  2 9 0 8,  1 3 0 5,  7 2 7,  - 1 6 5 3,  - 1 6 5 3,  - 1 2 7 0,  - 7 4 3,  - 1 2 3 5,  - 5 4 3,  2 1 1 2,  2 8 6 5,  5 5 3,  - 1 2 8 9,  - 1 1 7 4,  - 1 4 9 1,  7 1,  - 9 1 0,  - 1 4 6,  1 9 4 6,  2 4 8 7,  7 2 4,  - 1 5 6 8,  - 1 1 6 9,  - 2 3 5 7,  - 1 9 2 0,  - 1 2 2 7,  1 2 0 1,  3 1 3 2,  1 7 0,  - 1 7 6 8,  - 1 5 6 6,  - 9 1 0,  - 9 1 0,  - 1 7 1 5,  - 1 7 1 5,  - 2 7 4 3,  7 7 7,  2 6 3 1,  1 3 6 6,  - 1 1 1 8,  6 3 1,  - 1 4 2 4,  - 7 4 5,  - 6 0 7,  - 4 6 0,  1 8 5 3,  1 3 6 3,  - 1 7 0,  - 6 0 4,  <|<end_prompt>|> Answer:  - 1 4 4 6,  2 8 7,  - 1 6 1 6,  3 1 6,  3 2 1 7,  2 4 9 0,  - 5 8,  - 5 8,  - 2 7 4,  - 2 7 4,  /n ///### Instruction: Dataset description:The Electricity Transformer Temperature (ETT) is a crucial indicator in the electric power long-term deployment. This dataset consists of 2 years data from two separated counties in China. To explore the granularity on the Long sequence time-series forecasting (LSTF) problem, different subsets are created, {ETTh1, ETTh2} for 1-hour-level and ETTm1 for 15-minutes-level. Each data point consists of the target value ”oil temperature” and 6 power load features. The train/val/test is 12/4/4 months. . Statistics: The input has a minimum of  [0 0 0 0 0 0 0 3 5 2],  , a maximum of  [0 0 0 0 0 0 0 7 8 0], , , and a median of  [0 0 0 0 0 0 0 5 6 0],  . Task description: forecast the next 88 steps given the previous 783 steps information:  5 9 0,  5 4 2,  5 7 5,  5 8 3,  6 1 1,  5 7 5,  5 5 7,  5 3 9,  5 2 9,  5 2 9,  5 2 9,  5 3 1,  5 2 1,  5 2 1,  5 2 1,  5 1 9,  5 1 9,  4 9 3,  4 9 1,  4 8 3,  5 1 6,  5 2 9,  5 2 6,  5 2 1,  5 2 1,  5 1 6,  5 2 6,  5 2 1,  5 2 9,  5 1 1,  5 1 1,  4 8 0,  5 5 2,  5 0 6,  5 2 9,  5 0 6,  5 0 8,  5 9 3,  5 6 7,  5 9 5,  6 4 1,  5 7 0,  5 9 3,  5 9 3,  6 0 8,  6 1 1,  6 0 6,  6 2 4,  6 2 1,  5 8 5,  5 7 8,  6 5 4,  6 4 7,  6 6 7,  6 4 4,  6 2 1,  5 9 3,  6 4 4,  6 5 9,  6 3 9,  6 4 4,  6 3 6,  6 2 6,  6 6 4,  6 1 6,  6 7 5,  6 0 1,  6 7 2,  5 9 3,  5 9 8,  6 2 1,  5 7 5,  5 8 3,  6 1 1,  6 1 3,  5 9 5,  6 0 1,  5 8 5,  6 1 1,  6 1 6,  5 3 9,  5 4 9,  5 9 3,  5 5 7,  5 8 0,  5 8 8,  5 3 9,  5 6 0,  5 2 6,  5 2 1,  4 9 1,  4 9 3,  5 0 3,  4 7 0,  4 7 8,  4 9 3,  4 8 5,  4 8 0,  5 2 9,  5 1 6,  4 9 8,  5 0 3,  5 2 1,  5 3 7,  5 3 1,  5 4 4,  5 4 2,  5 3 7,  5 2 6,  5 3 7,  5 3 9,  5 2 9,  5 2 9,  5 1 1,  4 8 5,  4 9 6,  4 7 3,  4 7 3,  4 6 8,  4 6 5,  4 6 5,  4 7 0,  4 6 8,  4 6 5,  4 6 2,  4 6 0,  4 5 7,  3 9 9,  4 5 5,  4 7 8,  5 0 3,  4 8 8,  5 0 3,  5 6 5,  5 4 4,  6 0 3,  6 1 8,  5 6 5,  5 6 5,  6 2 1,  6 3 1,  5 9 5,  6 3 4,  6 4 9,  6 5 4,  6 7 7,  6 9 3,  6 9 0,  7 2 3,  6 6 7,  6 2 9,  6 0 8,  6 3 4,  5 9 5,  5 9 0,  6 1 8,  6 8 0,  6 2 4,  6 5 7,  6 8 7,  6 2 4,  6 4 9,  6 7 0,  6 5 2,  6 0 6,  5 4 9,  6 0 6,  6 1 3,  5 9 0,  5 7 0,  6 0 8,  6 1 6,  6 0 6,  6 3 9,  6 0 6,  6 2 9,  6 5 4,  6 4 7,  6 7 2,  6 1 8,  6 4 9,  6 6 4,  7 0 0,  6 5 9,  6 3 4,  6 3 9,  6 3 1,  5 2 1,  5 6 0,  5 4 9,  5 2 9,  6 1 6,  5 1 9,  5 9 0,  6 0 8,  6 3 9,  5 5 7,  5 7 5,  5 2 6,  5 4 4,  4 9 8,  5 1 4,  5 7 2,  5 1 6,  5 0 8,  4 9 3,  4 9 3,  4 8 5,  4 8 3,  4 7 8,  4 7 8,  4 7 3,  4 8 3,  4 7 8,  4 8 3,  4 8 5,  4 7 8,  4 7 8,  4 7 5,  4 7 8,  4 7 8,  4 7 8,  4 7 0,  4 7 5,  4 7 5,  4 2 9,  4 9 6,  5 1 4,  4 8 8,  5 0 1,  5 7 2,  5 5 7,  5 9 8,  5 6 5,  5 6 0,  5 9 5,  6 1 3,  6 1 3,  6 3 1,  6 1 1,  6 1 3,  5 7 8,  5 6 2,  6 0 6,  5 6 5,  5 8 8,  6 2 4,  5 7 8,  6 7 2,  6 1 1,  5 9 3,  5 7 5,  5 6 0,  5 8 5,  5 3 7,  5 5 7,  5 9 3,  5 6 5,  5 2 4,  5 2 1,  4 8 0,  5 0 3,  5 1 1,  5 4 7,  5 2 1,  5 1 1,  5 1 1,  4 9 6,  5 0 1,  5 1 6,  5 0 3,  5 6 5,  5 9 0,  6 1 3,  5 8 3,  5 5 7,  5 8 0,  5 4 9,  5 7 5,  5 5 2,  5 4 7,  4 9 6,  4 8 5,  4 6 5,  4 7 8,  4 9 1,  5 3 1,  5 4 9,  5 3 4,  5 8 3,  5 1 4,  5 9 5,  5 3 7,  4 8 8,  5 7 0,  5 7 5,  5 0 6,  5 1 4,  5 4 2,  5 1 6,  5 3 9,  5 1 4,  5 1 6,  5 2 4,  5 2 4,  5 1 4,  4 9 8,  4 9 3,  5 0 3,  5 0 1,  4 8 0,  4 8 3,  4 8 0,  4 8 3,  4 7 8,  4 8 0,  4 7 3,  4 7 5,  4 7 5,  4 7 3,  4 9 8,  5 3 1,  5 7 2,  5 3 9,  5 3 9,  5 7 5,  5 9 3,  5 9 8,  6 4 4,  6 3 6,  6 5 9,  6 6 7,  7 3 6,  6 6 2,  7 0 5,  7 2 6,  7 2 3,  7 4 1,  7 2 6,  7 8 0,  7 1 3,  7 1 6,  7 0 8,  6 5 4,  7 5 7,  7 2 1,  6 8 0,  6 7 2,  6 5 7,  6 3 9,  6 9 8,  6 2 6,  5 8 5,  6 5 7,  6 8 0,  5 4 2,  5 6 2,  5 5 2,  5 6 0,  6 0 8,  6 1 3,  5 9 3,  5 8 0,  5 5 4,  5 8 5,  6 2 6,  6 2 9,  6 2 4,  5 8 3,  5 0 1,  5 2 6,  5 2 6,  5 4 9,  5 6 7,  5 4 9,  5 2 9,  5 4 9,  5 5 4,  5 4 2,  4 8 8,  4 7 0,  4 8 5,  4 9 1,  5 2 1,  5 0 8,  5 5 2,  4 8 8,  4 8 5,  4 9 3,  5 1 6,  5 4 2,  4 9 3,  4 9 3,  5 3 9,  5 0 3,  5 0 1,  4 9 8,  4 9 1,  4 9 6,  4 8 5,  4 9 1,  4 3 9,  4 7 3,  4 7 0,  4 6 2,  4 7 3,  4 6 2,  4 6 0,  4 6 5,  4 6 2,  4 6 2,  4 6 2,  4 5 7,  4 6 0,  4 6 0,  3 9 6,  4 8 8,  5 1 4,  3 5 2,  4 1 1,  4 4 2,  5 1 4,  5 4 4,  4 9 8,  5 4 9,  4 9 6,  5 4 4,  5 3 9,  5 2 1,  4 8 8,  5 4 2,  5 5 7,  5 0 8,  5 7 5,  5 8 5,  5 1 9,  4 8 5,  4 5 5,  5 0 8,  4 6 8,  5 1 4,  5 3 1,  4 9 1,  5 1 4,  4 9 1,  5 0 8,  5 3 1,  5 1 1,  5 2 1,  4 6 2,  4 7 3,  5 0 8,  5 3 1,  5 6 0,  5 6 7,  5 8 5,  6 1 3,  5 9 0,  5 6 0,  5 9 0,  6 5 2,  6 8 2,  6 3 4,  6 9 3,  6 7 7,  6 6 2,  6 3 6,  6 4 7,  6 4 4,  6 5 2,  6 2 6,  6 2 6,  6 5 7,  6 2 1,  5 8 0,  5 4 9,  5 8 0,  5 9 0,  5 9 5,  5 6 7,  5 9 3,  6 3 9,  6 1 1,  5 9 3,  5 8 8,  6 1 3,  6 1 1,  6 2 6,  5 9 8,  5 6 2,  5 9 5,  5 6 7,  5 5 2,  5 6 5,  5 6 5,  5 6 5,  5 4 9,  5 4 9,  5 4 9,  5 3 4,  5 4 4,  5 3 7,  5 2 6,  5 2 9,  5 1 9,  5 2 9,  5 3 1,  5 2 4,  5 2 1,  5 0 3,  5 0 3,  5 0 6,  5 1 4,  5 7 0,  5 4 9,  5 6 0,  5 3 9,  6 7 2,  6 7 5,  6 1 1,  6 2 9,  6 2 9,  5 8 3,  6 5 7,  6 6 7,  5 9 8,  6 4 4,  6 1 6,  6 5 9,  7 1 3,  6 8 7,  6 5 7,  6 7 7,  6 5 9,  6 6 4,  5 8 3,  6 3 1,  6 5 7,  6 7 0,  6 8 5,  6 3 9,  6 5 7,  6 2 6,  6 6 2,  6 0 6,  6 6 2,  6 3 4,  5 8 3,  6 2 6,  6 5 4,  5 5 7,  5 3 4,  5 8 8,  6 2 9,  6 6 4,  5 4 2,  5 1 1,  5 1 1,  5 0 8,  5 5 2,  5 4 4,  5 2 1,  5 2 1,  5 4 4,  5 5 7,  5 1 4,  5 1 1,  5 0 6,  5 8 3,  5 2 1,  4 7 3,  4 6 5,  4 9 3,  4 8 5,  4 8 8,  4 9 6,  5 3 1,  5 0 8,  5 0 6,  5 1 6,  5 5 4,  5 1 9,  5 7 8,  5 4 7,  5 4 2,  5 8 0,  5 2 6,  5 0 6,  5 0 3,  5 0 6,  4 9 1,  5 0 3,  5 6 2,  5 3 7,  5 1 1,  5 0 6,  5 2 1,  5 2 4,  4 9 8,  4 9 1,  4 9 8,  5 0 1,  4 9 1,  4 9 3,  4 8 8,  4 9 8,  4 9 8,  4 3 9,  4 8 5,  5 8 5,  5 3 7,  5 3 7,  5 7 8,  5 8 0,  5 9 8,  6 0 6,  6 1 3,  5 7 5,  5 4 4,  6 2 1,  6 1 3,  6 0 8,  6 5 2,  6 1 6,  6 5 4,  6 4 4,  7 0 8,  6 9 5,  6 8 2,  6 8 0,  6 8 2,  7 1 8,  6 8 0,  6 7 2,  6 2 6,  6 8 2,  6 5 7,  6 4 9,  6 5 4,  6 6 7,  6 4 4,  6 2 4,  6 2 6,  6 3 9,  6 1 8,  6 5 4,  5 8 0,  5 9 8,  5 9 0,  6 2 9,  6 2 6,  6 2 4,  6 3 1,  6 0 8,  6 1 6,  6 5 7,  6 3 1,  6 2 4,  6 2 1,  6 2 1,  5 6 5,  5 6 2,  5 6 0,  5 6 2,  5 6 0,  5 5 7,  5 3 9,  4 8 8,  4 9 8,  5 2 4,  5 8 0,  6 0 6,  5 6 2,  5 8 3,  6 1 6,  5 6 2,  6 0 1,  5 8 5,  5 7 5,  6 2 4,  5 7 5,  5 5 4,  6 1 6,  6 2 1,  5 9 5,  5 8 8,  5 6 5,  5 8 8,  5 9 3,  5 4 9,  5 3 1,  5 3 1,  5 3 1,  5 1 1,  5 2 1,  5 0 8,  5 0 3,  4 9 1,  4 9 8,  4 9 6,  5 0 1,  4 9 1,  4 9 3,  5 1 6,  5 2 4,  6 1 1,  5 9 0,  5 6 5,  5 4 9,  5 7 0,  6 0 6,  5 9 3,  6 4 4,  6 2 4,  6 5 2,  6 4 4,  6 9 5,  6 5 4,  6 6 4,  6 4 7,  6 8 5,  7 1 3,  6 5 7,  6 8 0,  6 6 7,  6 8 5,  6 4 4,  6 8 7,  6 6 7,  7 2 6,  6 2 9,  6 4 4,  6 3 9,  6 1 6,  6 5 7,  7 2 1,  7 0 5,  6 9 0,  7 4 4,  6 4 1,  6 7 2,  6 6 4,  6 3 9,  5 8 0,  6 3 4,  6 2 6,  5 7 2,  5 9 5,  6 3 4,  6 4 1,  6 1 1,  6 9 8,  5 5 7,  5 7 5,  6 2 9,  5 8 8,  6 1 6,  5 7 5,  5 8 5,  6 0 3,  6 0 3,  6 0 6,  5 5 4,  5 2 4,  5 1 6,  5 1 4,  4 9 3,  5 4 7,  5 1 4,  5 0 8,  5 1 4,  5 2 6,  5 3 1,  5 2 4,  5 2 1,  5 2 4,  5 3 7,  5 2 9,  5 2 4,  5 2 1,  5 2 1,  5 7 0,  5 4 7,  5 9 0,  5 4 2,  5 7 5,  5 8 3,  6 1 1,  5 7 5,  5 5 7,  5 3 9,  5 2 9,  5 2 9,  5 2 9,  5 3 1,  5 2 1,  5 2 1,  5 2 1,  5 1 9,  5 1 9,  4 9 3,  4 9 1,  4 8 3,  5 1 6,  5 2 9,  5 2 6,  5 2 1,  5 2 1,  5 1 6,  5 2 6,  5 2 1,  5 2 9,  5 1 1,  5 1 1,  4 8 0,  5 5 2,  5 0 6,  5 2 9,  5 0 6,  5 0 8,  5 9 3,  5 6 7,  5 9 5,  6 4 1,  5 7 0,  5 9 3,  5 9 3,  6 0 8,  6 1 1,  6 0 6,  6 2 4,  6 2 1,  5 8 5,  5 7 8,  6 5 4,  6 4 7,  6 6 7,  6 4 4,  6 2 1,  5 9 3,  6 4 4,  6 5 9,  6 3 9,  6 4 4,  6 3 6,  6 2 6,  6 6 4,  6 1 6,  6 7 5,  6 0 1,  6 7 2,  5 9 3,  5 9 8,  6 2 1,  5 7 5,  5 8 3,  6 1 1,  6 1 3,  5 9 5,  6 0 1,  5 8 5,  6 1 1,  6 1 6,  5 3 9,  5 4 9,  5 9 3,  5 5 7,  5 8 0,  5 8 8,  5 3 9,  5 6 0,  5 2 6,  5 2 1,  4 9 1,  4 9 3,  5 0 3,  4 7 0,  4 7 8,  4 9 3,  4 8 5,  4 8 0,  5 2 9,  5 1 6,  4 9 8,  5 0 3,  5 2 1,  5 3 7,  5 3 1,  5 4 4,  5 4 2,  5 3 7,  5 2 6,  5 3 7,  5 3 9,  5 2 9,  5 2 9,  5 1 1,  4 8 5,  4 9 6,  4 7 3,  4 7 3,  4 6 8,  4 6 5,  4 6 5,  4 7 0,  4 6 8,  4 6 5,  4 6 2,  4 6 0,  4 5 7,  3 9 9,  4 5 5,  4 7 8,  5 0 3,  4 8 8,  5 0 3,  5 6 5,  5 4 4,  6 0 3,  6 1 8,  5 6 5,  5 6 5,  6 2 1,  6 3 1,  5 9 5,  6 3 4,  6 4 9,  6 5 4,  6 7 7,  6 9 3,  6 9 0,  7 2 3,  6 6 7,  6 2 9,  6 0 8,  6 3 4,  5 9 5,  5 9 0,  6 1 8,  6 8 0,  6 2 4,  6 5 7,  6 8 7,  6 2 4,  6 4 9,  6 7 0,  6 5 2,  6 0 6,  5 4 9,  6 0 6,  6 1 3,  5 9 0,  5 7 0,  6 0 8,  6 1 6,  6 0 6,  6 3 9,  6 0 6,  6 2 9,  6 5 4,  6 4 7,  6 7 2,  6 1 8,  6 4 9,  6 6 4,  7 0 0,  6 5 9,  6 3 4,  6 3 9,  6 3 1,  5 2 1,  5 6 0,  5 4 9,  5 2 9,  6 1 6,  5 1 9,  5 9 0,  6 0 8,  6 3 9,  5 5 7,  5 7 5,  5 2 6,  5 4 4,  4 9 8,  5 1 4,  5 7 2,  5 1 6,  5 0 8,  4 9 3,  4 9 3,  4 8 5,  4 8 3,  4 7 8,  4 7 8,  4 7 3,  4 8 3,  4 7 8,  4 8 3,  4 8 5,  4 7 8,  4 7 8,  4 7 5,  4 7 8,  4 7 8,  4 7 8,  4 7 0,  4 7 5,  4 7 5,  4 2 9,  4 9 6,  5 1 4,  4 8 8,  5 0 1,  5 7 2,  5 5 7,  5 9 8,  5 6 5,  5 6 0,  5 9 5,  6 1 3,  6 1 3,  6 3 1,  6 1 1,  6 1 3,  5 7 8,  5 6 2,  6 0 6,  5 6 5,  5 8 8,  6 2 4,  5 7 8,  6 7 2,  6 1 1,  5 9 3,  5 7 5,  5 6 0,  5 8 5,  5 3 7,  5 5 7,  5 9 3,  5 6 5,  5 2 4,  5 2 1,  4 8 0,  5 0 3,  5 1 1,  5 4 7,  5 2 1,  5 1 1,  5 1 1,  4 9 6,  5 0 1,  5 1 6,  5 0 3,  5 6 5,  5 9 0,  6 1 3,  5 8 3,  5 5 7,  5 8 0,  5 4 9,  5 7 5,  5 5 2,  5 4 7,  4 9 6,  4 8 5,  4 6 5,  4 7 8,  4 9 1,  5 3 1,  5 4 9,  5 3 4,  5 8 3,  5 1 4,  5 9 5,  5 3 7,  4 8 8,  5 7 0,  5 7 5,  5 0 6,  5 1 4,  5 4 2,  5 1 6,  5 3 9,  5 1 4,  5 1 6,  5 2 4,  5 2 4,  5 1 4,  4 9 8,  4 9 3,  5 0 3,  5 0 1,  4 8 0,  4 8 3,  4 8 0,  4 8 3,  4 7 8,  4 8 0,  4 7 3,  4 7 5,  4 7 5,  4 7 3,  4 9 8,  5 3 1,  5 7 2,  5 3 9,  5 3 9,  5 7 5,  5 9 3,  5 9 8,  6 4 4,  6 3 6,  6 5 9,  6 6 7,  7 3 6,  6 6 2,  7 0 5,  7 2 6,  7 2 3,  7 4 1,  7 2 6,  7 8 0,  7 1 3,  7 1 6,  7 0 8,  6 5 4,  7 5 7,  7 2 1,  6 8 0,  6 7 2,  6 5 7,  6 3 9,  6 9 8,  6 2 6,  5 8 5,  6 5 7,  6 8 0,  5 4 2,  5 6 2,  5 5 2,  5 6 0,  6 0 8,  6 1 3,  5 9 3,  5 8 0,  5 5 4,  5 8 5,  6 2 6,  6 2 9,  6 2 4,  5 8 3,  5 0 1,  5 2 6,  5 2 6,  5 4 9,  5 6 7,  5 4 9,  5 2 9,  5 4 9,  5 5 4,  5 4 2,  4 8 8,  4 7 0,  4 8 5,  4 9 1,  5 2 1,  5 0 8,  5 5 2,  4 8 8,  4 8 5,  4 9 3,  5 1 6,  5 4 2,  4 9 3,  4 9 3,  5 3 9,  5 0 3,  5 0 1,  4 9 8,  4 9 1,  4 9 6,  4 8 5,  4 9 1,  4 3 9,  4 7 3,  4 7 0,  4 6 2,  4 7 3,  4 6 2,  4 6 0,  4 6 5,  4 6 2,  4 6 2,  4 6 2,  4 5 7,  4 6 0,  4 6 0,  3 9 6,  4 8 8,  5 1 4,  3 5 2,  4 1 1,  4 4 2,  5 1 4,  5 4 4,  4 9 8,  5 4 9,  4 9 6,  5 4 4,  5 3 9,  5 2 1,  4 8 8,  5 4 2,  5 5 7,  5 0 8,  5 7 5,  5 8 5,  5 1 9,  4 8 5,  4 5 5,  5 0 8,  4 6 8,  5 1 4,  5 3 1,  4 9 1,  5 1 4,  4 9 1,  5 0 8,  5 3 1,  5 1 1,  5 2 1,  4 6 2,  4 7 3,  5 0 8,  5 3 1,  5 6 0,  5 6 7,  5 8 5,  6 1 3,  5 9 0,  5 6 0,  5 9 0,  6 5 2,  6 8 2,  6 3 4,  6 9 3,  6 7 7,  6 6 2,  6 3 6,  6 4 7,  6 4 4,  6 5 2,  6 2 6,  6 2 6,  6 5 7,  6 2 1,  5 8 0,  5 4 9,  5 8 0,  5 9 0,  5 9 5,  5 6 7,  5 9 3,  6 3 9,  6 1 1,  5 9 3,  5 8 8,  6 1 3,  6 1 1,  6 2 6,  5 9 8,  5 6 2,  5 9 5,  5 6 7,  5 5 2,  5 6 5,  5 6 5,  5 6 5,  5 4 9,  5 4 9,  5 4 9,  5 3 4,  5 4 4,  5 3 7,  5 2 6,  5 2 9,  5 1 9,  5 2 9,  5 3 1,  5 2 4,  5 2 1,  5 0 3,  5 0 3,  5 0 6,  5 1 4,  5 7 0,  5 4 9,  5 6 0,  5 3 9,  6 7 2,  6 7 5,  6 1 1,  6 2 9,  6 2 9,  5 8 3,  6 5 7,  6 6 7,  5 9 8,  6 4 4,  6 1 6,  6 5 9,  7 1 3,  6 8 7,  6 5 7,  6 7 7,  6 5 9,  6 6 4,  5 8 3,  6 3 1,  6 5 7,  6 7 0,  6 8 5,  6 3 9,  6 5 7,  6 2 6,  6 6 2,  6 0 6,  6 6 2,  6 3 4,  5 8 3,  6 2 6,  6 5 4,  5 5 7,  5 3 4,  5 8 8,  6 2 9,  6 6 4,  5 4 2,  5 1 1,  5 1 1,  5 0 8,  5 5 2,  5 4 4,  5 2 1,  5 2 1,  5 4 4,  5 5 7,  5 1 4,  5 1 1,  5 0 6,  5 8 3,  5 2 1,  4 7 3,  4 6 5,  4 9 3,  4 8 5,  4 8 8,  4 9 6,  5 3 1,  5 0 8,  5 0 6,  5 1 6,  5 5 4,  5 1 9,  5 7 8,  5 4 7,  5 4 2,  5 8 0,  5 2 6,  5 0 6,  5 0 3,  5 0 6,  4 9 1,  5 0 3,  5 6 2,  5 3 7,  5 1 1,  5 0 6,  5 2 1,  5 2 4,  4 9 8,  4 9 1,  4 9 8,  5 0 1,  4 9 1,  4 9 3,  4 8 8,  4 9 8,  4 9 8,  4 3 9,  4 8 5,  5 8 5,  5 3 7,  5 3 7,  5 7 8,  5 8 0,  5 9 8,  6 0 6,  6 1 3,  5 7 5,  5 4 4,  6 2 1,  6 1 3,  6 0 8,  6 5 2,  6 1 6,  6 5 4,  6 4 4,  7 0 8,  6 9 5,  6 8 2,  6 8 0,  6 8 2,  7 1 8,  6 8 0,  6 7 2,  6 2 6,  6 8 2,  6 5 7,  6 4 9,  6 5 4,  6 6 7,  6 4 4,  6 2 4,  6 2 6,  6 3 9,  6 1 8,  6 5 4,  5 8 0,  5 9 8,  5 9 0,  6 2 9,  6 2 6,  6 2 4,  6 3 1,  6 0 8,  6 1 6,  6 5 7,  6 3 1,  6 2 4,  6 2 1,  6 2 1,  5 6 5,  5 6 2,  5 6 0,  5 6 2,  5 6 0,  5 5 7,  5 3 9,  4 8 8,  4 9 8,  5 2 4,  5 8 0,  6 0 6,  5 6 2,  5 8 3,  6 1 6,  5 6 2,  6 0 1,  5 8 5,  5 7 5,  6 2 4,  5 7 5,  5 5 4,  6 1 6,  6 2 1,  5 9 5,  5 8 8,  5 6 5,  5 8 8,  5 9 3,  5 4 9,  5 3 1,  5 3 1,  5 3 1,  5 1 1,  5 2 1,  5 0 8,  5 0 3,  4 9 1,  4 9 8,  4 9 6,  5 0 1,  4 9 1,  4 9 3,  5 1 6,  5 2 4,  6 1 1,  5 9 0,  5 6 5,  5 4 9,  5 7 0,  6 0 6,  5 9 3,  6 4 4,  6 2 4,  6 5 2,  6 4 4,  6 9 5,  6 5 4,  6 6 4,  6 4 7,  6 8 5,  7 1 3,  6 5 7,  6 8 0,  6 6 7,  6 8 5,  6 4 4,  6 8 7,  6 6 7,  7 2 6,  6 2 9,  6 4 4,  6 3 9,  6 1 6,  6 5 7,  7 2 1,  7 0 5,  6 9 0,  7 4 4,  6 4 1,  6 7 2,  6 6 4,  6 3 9,  5 8 0,  6 3 4,  6 2 6,  5 7 2,  5 9 5,  6 3 4,  6 4 1,  6 1 1,  6 9 8,  5 5 7,  5 7 5,  6 2 9,  5 8 8,  6 1 6,  5 7 5,  5 8 5,  6 0 3,  6 0 3,  6 0 6,  5 5 4,  5 2 4,  5 1 6,  5 1 4,  4 9 3,  5 4 7,  5 1 4,  5 0 8,  5 1 4,  5 2 6,  5 3 1,  5 2 4,  5 2 1,  5 2 4,  5 3 7,  5 2 9,  5 2 4,  5 2 1,  5 2 1,  5 7 0,  5 4 7,  5 5 4,  5 4 9,  5 1 1,  5 2 6,  5 2 1,  4 9 8,  4 9 8,  4 8 8,  4 8 8,  4 8 3,  4 8 5,  4 8 5,  4 7 8,  4 7 5,  4 7 8,  4 8 3,  4 8 8,  4 2 7,  4 8 8,  5 2 1,  5 3 7,  5 8 5,  5 8 3,  6 2 1,  5 7 5,  6 2 4,  6 5 4,  6 5 2,  6 5 4,  6 4 4,  6 3 6,  7 1 8,  6 4 4,  6 5 7,  7 2 1,  7 1 8,  6 9 0,  6 8 0,  6 6 2,  6 8 0,  7 1 8,  6 5 9,  7 0 8,  6 7 5,  6 9 0,  6 7 0,  6 8 7,  6 4 1,  6 3 6,  6 1 3,  6 6 7,  6 2 1,  6 4 4,  5 9 0,  5 5 2,  5 7 2,  5 8 0,  6 0 6,  6 0 8,  6 2 4,  6 2 9,  5 9 8,  5 7 8,  6 2 4,  6 6 2,  5 5 4,  5 1 9,  5 1 6,  5 6 0,  5 3 9,  5 9 8,  5 8 0,  5 9 0,  5 7 0,  6 0 6,  5 0 3,  5 2 6,  4 9 8,  4 9 3,  4 9 6,  5 1 6,  5 3 4,  6 1 1,  5 4 9,  5 6 5,  5 6 5,  5 5 4,  5 2 9, </s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatting_prompts_func(dataset[\"test\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54706c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a091770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "  return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583d536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa29b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"7 3 4,  7 5 6,  7 9 2,  7 8 9,  7 8 9,  7 6 8,  7 3 0,  6 9 0,  6 4 9,  6 1 8,  5 9 6,  5 9 6,  6 1 4,  6 4 3,  6 8 6,  7 4 3,  7 8 7,  8 1 1,  8 2 0,  8 0 4,  7 8 2,  7 2 7,  6 9 7,  6 8 3,  6 6 8,  6 7 2,  6 8 0,  6 9 3,  6 8 8,  6 8 2,  6 6 8,  6 4 5,  6 5 7,  6 7 1,  6 9 6,  7 4 6,  7 8 0,  8 0 9,  7 9 1,  7 5 9,  7 1 5,  6 3 1,  5 7 5,  5 1 8,  4 7 1,  4 5 3,  4 5 2,  4 5 9,  4 9 6,  5 4 7,  5 9 2,  6 4 4,  6 8 5,  7 1 2,  7 2 5,  7 2 7,  7 1 8,  7 1 3,  7 0 1,  6 8 4,  6 7 0,  6 6 4,  6 3 7,  6 3 1,  6 1 0,  5 8 6,  5 6 0,  5 4 9,  5 2 3,  5 2 1,  5 3 0,  5 5 8,  5 6 7,  5 8 5,  6 0 4,  6 1 6,  6 3 0,  6 3 8,  6 6 2,  6 7 6,  6 8 6,  7 0 0,  7 0 6,  7 3 2,  7 4 6,  7 6 0,  7 8 3,  7 8 7,  8 0 6,  8 0 5,  8 3 2,  8 3 4,  8 4 5,  8 3 5,  8 4 1,  8 2 8,  8 2 0,  8 2 2,  8 4 4,  8 7 5,  9 1 3,  9 3 9,  9 5 0,  9 2 8,  9 0 7,  8 9 4,  8 8 4,  8 8 4,  8 8 3,  8 7 2,  8 5 8,  8 4 0,  8 1 4,  8 0 5,  7 8 9,  7 6 8,  7 5 7,  7 5 0,  7 4 0,  7 3 4,  7 3 6,  7 4 4,  7 0 0,  7 3 3,  7 7 0,  7 9 5,  8 1 8,  8 3 5,  8 3 9,  8 5 4,  8 6 0,  8 7 7,  8 8 1,  8 7 4,  8 5 4,  8 2 1,  7 9 8,  7 7 0,  7 5 2,  7 4 9,  7 5 3,  7 4 8,  7 6 4,  7 6 9,  7 7 5,  7 8 3,  7 8 3,  7 9 0,  7 9 2,  7 8 9,  8 0 6,  8 2 7,  8 4 5,  8 7 0,  8 9 0,  9 0 0,  9 1 4,  9 1 3,  9 2 3,  9 1 2,  9 0 4,  8 8 1,  8 4 7,  8 2 5,  7 7 9,  7 7 3,  7 5 6,  7 5 1,  7 4 6,  7 4 1,  7 4 6,  7 4 5,  7 4 6,  7 5 1,  7 4 6,  7 4 4,  7 2 0,  7 1 1,  6 8 8,  6 5 1,  6 3 4,  6 1 2,  5 9 4,  6 0 3,  6 2 1,  6 4 3,  6 6 8,  6 8 4,  7 0 8,  7 3 0,  7 3 5,  7 3 7,  7 4 4,  7 1 8,  7 1 2,  7 0 2,  6 8 2,  6 7 7,  6 6 5,  6 6 6,  6 6 3,  6 6 8,  6 6 7,  6 7 4,  6 5 6,  6 3 1,  6 1 6,  5 9 3,  5 9 6,  6 0 6,  6 2 9,  6 6 2,  6 9 4,  7 1 7,  7 4 1,  7 4 2,  7 6 3,  7 5 1,  7 6 5,  7 7 3,  7 7 6,  7 6 1,  7 7 3,  7 7 0,  7 6 5,  7 6 3,  7 7 5,  7 8 2,  7 8 0,  7 9 0,  7 9 8,  8 0 9,  8 2 2,  8 2 9,  8 3 7,  8 3 4,  8 3 7,  8 3 6,  8 2 8,  8 2 0,  8 1 6,  8 3 1,  8 2 4,  8 3 1,  8 4 6,  8 5 7,  8 6 1,  8 6 4,  8 6 7,  8 5 8,  8 3 5,  8 0 8,  7 8 3,  7 5 2,  7 4 3,  7 6 0,  7 8 0,  7 8 7,  8 0 5,  8 3 0,  8 4 7,  8 6 3,  8 7 7,  8 7 9,  8 6 4,  8 3 5,  8 1 9,  8 0 1,  7 8 5,  7 6 9,  7 5 5,  7 3 5,  7 1 9,  7 0 6,  7 1 6,  7 1 9,  7 3 5,  7 5 6,  7 8 3,  7 8 7,  8 0 9,  8 0 2,  7 9 6,  7 7 3,  7 5 2,  7 3 5,  7 1 4,  7 1 3,  6 9 8,  6 9 6,  6 9 8,  6 9 8,  7 0 3,  7 0 4,  7 0 6,  7 2 1,  7 2 3,  7 4 0,  7 4 6,  7 6 0,  7 7 1,  7 4 5,  7 5 3,  7 4 4,  7 3 3,  7 1 3,  6 9 2,  6 7 0,  6 6 6,  6 5 8,  6 7 5,  7 1 3,  7 3 4,  7 6 3,  7 7 9,  7 8 8,  7 9 2,  7 9 3,  7 9 5,  7 9 8,  8 1 6,  8 4 5,  8 6 4,  8 9 8,  9 0 7,  8 9 8,  8 7 0,  8 2 5,  7 8 8,  7 3 3,  6 9 4,  6 6 0,  6 4 6,  6 4 6,  6 5 1,  6 5 9,  6 6 3,  6 7 2,  6 8 2,  6 7 5,  6 8 0,  6 8 1,  6 7 3,  6 9 2,  7 0 5,  7 4 1,  7 7 3,  8 1 8,  8 3 5,  8 4 7,  8 5 3,  8 5 9,  8 5 4,  8 5 5,  8 3 2,  8 2 7,  8 0 1,  7 9 5,  7 8 9,  7 8 3,  7 8 9,  7 8 1,  7 7 5,  7 7 5,  7 8 1,  8 0 7,  8 3 0,  8 6 6,  8 9 5,  9 1 3,  9 3 7,  9 5 6,  9 5 8,  9 6 6,  9 6 5,  9 5 5,  9 5 3,  9 3 3,  8 7 8,  8 5 4,  8 3 2,  8 0 3,  7 7 6,  7 5 0,  7 1 0,  6 9 9,  6 8 2,  6 7 1,  6 7 5,  6 8 1,  6 9 3,  7 1 9,  7 3 3,  7 4 4,  7 5 3,  7 4 2,  7 4 8,  7 4 6,  7 5 3,  7 5 3,  7 4 5,  7 4 0,  7 3 4,  7 2 3,  7 2 1,  7 3 0,  7 1 7,  6 9 5,  6 9 9,  6 8 2,  6 8 2,  6 7 4,  6 7 4,  6 6 2,  6 3 6,  6 2 2,  6 0 3,  5 9 7,  5 9 0,  5 9 1,  6 0 2,  6 1 2,  6 2 3,  6 2 3,  6 2 9,  6 3 9,  6 3 9,  6 3 1,  6 2 6,  6 2 1,  6 1 0,  6 0 0,  6 1 1,  6 1 5,  6 3 2,  6 5 4,  6 6 8,  7 0 0,  7 0 4,  7 2 1,  7 1 5,  7 2 1,  7 1 4,  7 1 7,  7 2 1,  7 2 8,  7 4 2,  7 5 7,  7 6 5,  7 8 4,  7 9 4,  8 0 9,  8 2 9,  8 4 7,  8 7 5,  8 8 7,  9 0 9,  9 1 0,  9 1 2,  8 9 6,  8 8 0,  8 6 9,  8 3 6,  8 1 7,  7 7 8,  7 6 1,  7 4 7,  7 2 7,  7 3 7,  7 3 3,  7 3 5,  7 5 8,  7 2 7,  7 2 5,  7 1 4,  7 0 0,  6 9 2,  7 1 0,  7 1 7,  7 1 6,  7 2 5,  7 2 9,  7 3 1,  7 3 9,  7 4 5,  7 6 3,  7 6 4,  7 7 1,  7 7 0,  7 7 8,  7 8 3,  7 9 5,  8 0 4,  8 3 3,  8 5 8,  8 7 5,  8 9 6,  8 9 4,  8 8 5,  8 6 5,  8 4 1,  8 1 0,  7 8 4,  7 6 9,  7 6 2,  7 5 2,  7 3 8,  7 4 5,  7 3 6,  7 3 7,  7 1 0,  6 8 8,  6 6 6,  6 4 2,  6 1 2,  6 0 0,  6 0 0,  5 9 2,  5 8 5,  5 8 9,  5 9 1,  5 8 0,  5 6 7,  5 7 0,  5 6 4,  5 9 1,  6 1 5,  6 4 3,  6 4 9,  6 6 2,  6 5 7,  6 5 0,  6 4 4,  6 6 6,  6 5 5,  6 7 0,  6 6 7,  6 8 4,  7 1 2,  7 3 2,  7 7 0,  8 1 8,  8 6 4,  8 9 9,  9 0 9,  9 0 0,  8 6 9,  8 1 1,  7 6 7,  7 4 3,  7 4 6,  7 6 1,  8 0 3,  8 4 5,  8 9 0,  9 1 1,  9 3 0,  9 3 6,  9 2 0,  9 0 8,  8 8 1,  8 5 7,  8 5 1,  8 5 1,  8 4 5,  8 4 1,  8 4 3,  8 2 3,  8 0 8,  7 8 5,  7 8 9,  7 9 3,  7 9 1,  8 2 0,  8 2 6,  8 2 4,  8 2 5,  8 2 0,  8 2 3,  7 9 6,  8 0 2,  7 8 8,  7 8 3,  7 7 9,  7 8 0,  7 9 7,  7 8 6,  7 8 1,  7 7 1,  7 3 6,  7 2 0,  7 1 2,  7 0 6,  7 2 1,  7 3 8,  7 5 5,  7 6 7,  7 8 0,  7 7 5,  7 7 7,  7 8 3,  7 7 3,  7 6 9,  7 8 7,  7 9 1,  8 2 7,  8 4 9,  8 6 6,  8 9 4,  8 9 2,  8 8 6,  8 6 4,  8 5 2,  8 3 4,  8 2 3,  8 4 1,  8 5 3,  8 6 9,  8 8 6,  8 8 3,  8 8 0,  8 5 3,  8 1 3,  7 7 3,  7 3 1,  7 0 0,  6 7 2,  6 6 0,  6 5 2,  6 5 7,  6 5 1,  6 5 4,  6 5 8,  6 6 4,  6 2 9,  6 3 8,  6 4 2,  6 5 7,  6 6 1,  6 7 4,  6 6 7,  6 6 4,  6 7 4,  6 6 8,  6 6 1,  6 6 1,  6 6 9,  6 7 6,  6 8 5,  7 0 2,  7 1 0,  7 2 6,  7 1 5,  7 2 2,  7 0 0,  6 9 4,  6 9 6,  6 9 3,  6 9 9,  7 0 3,  7 0 3,  6 9 7,  6 9 3,  6 9 4,  6 7 2,  6 6 4,  6 4 4,  6 4 2,  6 2 8,  6 4 0,  6 5 7,  6 8 1,  7 0 9,  7 3 8,  7 7 9,  8 0 0,  8 3 5,  8 3 1,  8 3 7,  8 4 1,  8 4 0,  8 3 6,  8 3 0,  8 3 9,  8 4 3,  8 4 3,  8 6 0,  8 7 0,  8 8 4,  8 8 9,  8 9 5,  9 1 0,  9 1 4,  9 0 3,  9 1 7,  8 9 0,  8 7 9,  8 5 1,  8 3 2,  8 1 3,  7 8 5,  7 5 6,  7 3 8,  7 1 9,  7 0 4,  7 1 1,  7 0 7,  7 0 2,  7 0 2,  6 8 9,  6 7 3,  6 6 0,  6 4 1,  6 3 4,  6 3 3,  6 4 2,  6 7 7,  7 1 3,  7 6 1,  8 0 3,  8 3 8,  8 4 7,  8 3 7,  8 2 5,  7 8 2,  7 6 4,  7 3 7,  7 1 3,  7 2 4,  7 3 7,  7 3 4,  7 4 1,  7 4 7,  7 4 4,  7 2 4,  7 3 0,  7 2 4,  7 2 4,  7 1 0,  6 9 6,  6 9 1,  6 6 4,  6 5 5,  6 3 7,  6 2 5,  6 1 0,  5 9 7,  5 8 9,  5 7 7,  5 5 0,  5 3 3,  5 2 3,  5 0 6,  4 9 4,  5 0 9,  5 2 3,  5 3 3,  5 5 2,  5 7 4,  5 8 6,  5 9 1,  6 1 0,  6 4 7,  6 6 7,  7 0 1,  7 3 1,  7 6 7,  7 7 3,  7 7 9,  7 7 5,  7 5 2,  7 4 2,  7 2 3,  7 3 7,  7 6 8,  8 0 2,  8 5 8,  9 2 9,  9 8 0,  9 9 6,  1 0 0 0,  9 6 0,  9 0 7,  8 4 2,  8 0 8,  7 8 4,  7 7 1,  7 9 1,  8 0 4,  8 1 5,  8 2 9,  8 2 4,  8 2 0,  8 0 6,  7 7 5,  7 6 7,  7 5 3,  7 3 0,  7 1 7,  7 0 6,  6 9 9,  6 9 7,  7 0 1,  7 0 9,  7 1 4,  7 0 9, \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2461654b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_response\u001b[49m(prompt, trainer\u001b[38;5;241m.\u001b[39mmodel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_response' is not defined"
     ]
    }
   ],
   "source": [
    "generate_response(prompt, trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddf2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38351f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66732d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "421afa5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./data/prompt3/\",\n",
    "    num_train_epochs=5,\n",
    "    #max_steps = 1500,\n",
    "    save_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=1,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    eval_steps=5,\n",
    "    \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    warmup_steps=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    load_best_model_at_end=True,\n",
    "    #metric_for_best_model=exact_match_metric,\n",
    "    logging_dir='./logs_f/prompt3/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c1375f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset= dataset[\"train\"],\n",
    "    eval_dataset= dataset[\"test\"],\n",
    "    peft_config= peft_params,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    max_seq_length=2048,\n",
    "    #compute_metrics=exact_match_metric,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9c4be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='461' max='4670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 461/4670 1:04:09 < 9:48:22, 0.12 it/s, Epoch 0.49/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5746cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=\"prompt3_1\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9077283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"data/prompt3_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435e6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc369b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d8fc259e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenizer(\"<|start_prompt|> Dataset description:The text discusses data from a Kaggle competition focused on decoding the human brain, specifically extracted from the train set of the competition's website. The training data includes MEG recordings and class labels (Face/Scramble) from 10 subjects labeled subject01 to subject10, while test data are from subjects labeled subject11 to subject16. Each subject has around 580-590 trials, with each trial comprising 1.5 seconds of MEG recording starting 0.5 seconds before the stimulus onset, along with a corresponding class label (Face: class 1, Scramble: class 0). The data has been down-sampled to 250Hz and high-pass filtered at 1Hz. Each trial includes 306 timeseries, recorded from 306 channels, resulting in a 3D data matrix (trial x channel x time) of size 580 x 306 x 375. All preprocessing steps were conducted using mne-python.. Statistics: The input has a minimum of  - 2 6 8 7, , a maximum of 1 0 1 9, , and a median of - 3 5 4, . Task description: forecast the next 7 0 0 0,  steps given the previous 5 5 0 0 0,  steps information: 3 9 7,  2 7 6,  3 0 9,  3 2 8,  3 5 0,  - 7 8 2,  - 6 5 4,  - 1 4 4,  - 5 0 6,  - 5 7 3,  - 1 2 4 0,  - 1 2 6 9,  - 2 1 5,  - 4 4 9,  2 2 0,  - 6 3 8,  - 6 1 5,  - 1 2 3,  - 1 3 5 8,  - 6 9 1,  - 9 9 4,  - 4 9 5,  - 7 8 8,  - 1 2 9 2,  - 1 7 5 4,  - 2 2 9 2,  - 2 6 8 7,  - 1 9 1 5,  3,  2 6 8,  1 8 8,  - 1 6 8,  - 1 1 1 0,  - 2 4 3 5,  - 1 8 9 0,  - 2 1 3 8,  - 9 9 2,  - 9 7,  3 3 3,  1 0 1 9,  3 3 5,  - 9 5 1,  - 1 0 0 0,  - 1 3 0 0,  2 5,  7 5 8,  4 6 8,  7 3,  3 3 7,  2 8 0,  3 8 2,  4 0 7,  - 7 1,  7 7,  - 2 5 9,  <|<end_prompt>|>Answer:  2 7 9,  - 2 1 1,  - 2 3,  - 9 8 5,  - 1 2 2 5,  - 6 7 5,  - 9 2 1, <|start_prompt|> Dataset description:The text discusses data from a Kaggle competition focused on decoding the human brain, specifically extracted from the train set of the competition's website. The training data includes MEG recordings and class labels (Face/Scramble) from 10 subjects labeled subject01 to subject10, while test data are from subjects labeled subject11 to subject16. Each subject has around 580-590 trials, with each trial comprising 1.5 seconds of MEG recording starting 0.5 seconds before the stimulus onset, along with a corresponding class label (Face: class 1, Scramble: class 0). The data has been down-sampled to 250Hz and high-pass filtered at 1Hz. Each trial includes 306 timeseries, recorded from 306 channels, resulting in a 3D data matrix (trial x channel x time) of size 580 x 306 x 375. All preprocessing steps were conducted using mne-python.. Statistics: The input has a minimum of  - 1 4 9 6, , a maximum of 1 7 9 6, , and a median of 2 0 2, . Task description: forecast the next 7 0 0 0,  steps given the previous 5 5 0 0 0,  steps information: - 1 1 1 4,  - 1 4 4 6,  - 1 4 1 7,  - 1 4 9 6,  - 1 4 3 3,  - 5 4 9,  1 0 8 5,  - 8 1 9,  1 0 2 1,  2 2 8,  9 8 4,  1 6 4 9,  - 4 6 9,  1 1 3 1,  8 6 3,  5 0 2,  1 4 2 3,  - 2 1 0,  7 9 3,  - 2 0 0,  - 1 0 6 3,  9 3 7,  - 1 4 5 3,  7 6 8,  - 1 2 6 7,  - 4 0 3,  1 0 5 6,  - 6 8 3,  5 3 4,  4 2 9,  - 9 4 7,  1 6 1 2,  - 3 7,  - 7 9,  - 1 3 9 4,  - 1 2 4 6,  1 3 2 2,  - 2 8 0,  - 5 1 1,  2 9 4,  - 9 7 3,  1 7 9 6,  - 7 8 3,  - 7 0 4,  6 1 8,  - 1 1 6 9,  6 2 3,  - 4 6 0,  1 7 5 2,  1 0 9 9,  1 6 1 1,  1 2 9 4,  4 3 1,  1 0 2 6,  8 4 2,  <|<end_prompt>|>Answer:  1 7 5,  1 1 5 1,  6 3,  - 9 5 7,  2 6 5,  1 2 4 7,  - 6 2, \")\n",
    "len(a[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7601c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0e943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
